{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Szkolenie ML/AI 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Uczenie nadzorowane (ang. supervised learning)**\n",
    "\n",
    "Dane uczące przekazywane algorytmowi zawierają pole z rozwiązaniem problemu (tzw. etygietę [ang. label]).\n",
    "\n",
    "***Problem klasyfikacji*** (ang. classification): przyporządkowanie wektorowi cech jego *klasy*.\n",
    "\n",
    "Przykład: \n",
    "\n",
    "| Czy szczeka? | Wielkość | Ilość kończyn | Waga    | Etykieta |\n",
    "|--------------|----------|---------------|---------|----------|\n",
    "| Tak          | Średnia  | 4             | Średnia | Pies     |\n",
    "| Nie          | Mała     | 4             | Mała    | Kot      |\n",
    "| Nie          | Duża     | 4             | Duża    | Krowa    |\n",
    "|--------------|----------|---------------|---------|----------|\n",
    "| Nie          | Mała     | 2             | Mała    | ???      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przykład zbiór irysów\n",
    "\n",
    "<div style=\"text-align: centered;\">\n",
    "    <img src=\"Zdjęcia/Szkolenie_2/Iris_decription.png\" alt=\"drawing\" style=\"width:900:\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Zdjęcia/Szkolenie_2/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych jako \"tablica / macierz\"\n",
    "data = pd.read_csv(\"Datasets/Iris.csv\")\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Species\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyrzucenie niepotrzebnej kolumny ID\n",
    "data.drop('Id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres 2D\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='SepalLengthCm', y='SepalWidthCm', hue='Species', data=data)\n",
    "plt.title('Sepal Length vs. Sepal Width')\n",
    "plt.xlabel('Sepal Length (cm)')\n",
    "plt.ylabel('Sepal Width (cm)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres 2D\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='PetalLengthCm', y='PetalWidthCm', hue='Species', data=data)\n",
    "plt.title('Sepal Length vs. Sepal Width')\n",
    "plt.xlabel('Sepal Length (cm)')\n",
    "plt.ylabel('Sepal Width (cm)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres 3D\n",
    "colors = {'Iris-setosa': 'blue', 'Iris-versicolor': 'orange', 'Iris-virginica': 'green'}\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(data['PetalLengthCm'], data['PetalWidthCm'], data['SepalLengthCm'], color=data['Species'].map(colors))\n",
    "\n",
    "ax.set_xlabel('Sepal Length (cm)')\n",
    "ax.set_ylabel('Sepal Width (cm)')\n",
    "ax.set_zlabel('Petal Length (cm)')\n",
    "ax.set_title('3D Plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rozkład próbek\n",
    "data.hist(edgecolor='black', linewidth=1.2)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,6)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Można stworzyć jeszcze wiele innych wizualizacji w zależności od tego co potrzebujemy (na przykład wykresy słupkowe, oszacować wariancję, obciążenie, standardową dewiację itp.). Przydatna jest wiedza ekspercka dotycząca zależności między cechami. Same korelacje możemy obliczyć z następującego kodu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8)) \n",
    "sns.heatmap(data.drop(\"Species\", axis=1).corr(),annot=True,cmap='grey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korelacja bilsko wartości -1 lub 1 oznacza kolejnko silnie ujemną lub silnie dodatnią czyli wraz ze zmianą jednej wartości druga maleje lub rośnie. Wartości bliskie 0 (śćiśle statystycznie oznaczają, że wartości są niezależne) oznaczają brak korelacji lub brak liniowej zależności\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: centered;\">\n",
    "    <img src=\"Zdjęcia/Szkolenie_2/Correlation.png\" alt=\"drawing\" style=\"width:900px;\"/>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Jeśli otrzymamy cechy o korelacji 1 lub -1 należy zastanowić się nad usunięciem jednej z nich, ponieważ przekazują one tę samą informację."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = sklearn.model_selection.train_test_split(data, test_size=0.3, random_state=42, shuffle=True)\n",
    "train, test = sklearn.model_selection.train_test_split(data, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbiór danych został podzielony na zbiór uczący (treningowy) i testowy. Jako że nie będzie przeprowadzone dostrajanie hiperparametróœ to można odpuścić sobie zbiór walidacyjny. **UWAGA** ukazana wyżej metoda jest \"brzydka\" w porządnym kodzie należy korzystać z metody k-krzyżowej walidacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.head(5))\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Trochę ładniejsza tabela :)\n",
    "print(tabulate(test.head(5), headers = 'keys', tablefmt = 'psql'))\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop(\"Species\", axis=1)\n",
    "train_Y = train[\"Species\"]\n",
    "\n",
    "test_X = test.drop(\"Species\", axis=1)\n",
    "test_Y = test[\"Species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(test_X.head(5), headers = 'keys', tablefmt = 'psql'))\n",
    "print(test_X.shape)\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "print(test_Y.head(5))\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stwórzmy 4 modele i sprawdżmy jak sobie radzą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression  # for Logistic Regression algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier  # for K nearest neighbours\n",
    "from sklearn import svm  #for Support Vector Machine (SVM) Algorithm\n",
    "from sklearn.tree import DecisionTreeClassifier #for using Decision Tree Algoithm\n",
    "\n",
    "from sklearn import metrics #for checking the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(train_X, train_Y)\n",
    "prediction = model.predict(test_X)\n",
    "print('The accuracy of the Logistic Regression is',metrics.accuracy_score(prediction,test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine (classification)\n",
    "\n",
    "model = svm.SVC() \n",
    "model.fit(train_X, train_Y)\n",
    "prediction = model.predict(test_X)\n",
    "print('The accuracy of the SVM is:', metrics.accuracy_score(prediction,test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "model=KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(train_X, train_Y)\n",
    "prediction = model.predict(test_X)\n",
    "print('The accuracy of the KNN is', metrics.accuracy_score(prediction,test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = []\n",
    "n_list = []\n",
    "\n",
    "for n in range(1,10):\n",
    "    model=KNeighborsClassifier(n_neighbors=n)\n",
    "    model.fit(train_X, train_Y)\n",
    "    prediction = model.predict(test_X)\n",
    "    knn.append(metrics.accuracy_score(prediction,test_Y))\n",
    "    n_list.append(n)\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.plot(n_list, knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "\n",
    "model=DecisionTreeClassifier()\n",
    "model.fit(train_X, train_Y)\n",
    "prediction = model.predict(test_X)\n",
    "print('The accuracy of the Decision Tree is',metrics.accuracy_score(prediction,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jak określić dokładność / celność w problemie klasyfikacji?\n",
    "\n",
    "Skupmy się na jednym modelu, np. Drzewie Decycyjnym, dla każdej predykcji modelu zwraca on swoją prognozę (etykietę). Tworząc \"wykres\" przewidywań rzeczywistych od modelu uzyskać można tzw. macierz konfucji. W przykładzie teoretycznym wygląda ona następująco:\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: centered;\">\n",
    "    <img src=\"Zdjęcia/Szkolenie_2/cm.png\" alt=\"drawing\" style=\"width:900px;\"/>\n",
    "</div>\n",
    "\n",
    "Czym są True positive?\n",
    "    Model poprawnie przewidział rzeczywistą etykietę (klasy 1)\n",
    "\n",
    "Czym są True negative?\n",
    "    Model poprawnie przewidział rzeczywistą etykietę (klasy 2)\n",
    "\n",
    "Czym są False positive?\n",
    "    Model żle przewidział rzeczywistą etyketę (klasy 2)\n",
    "\n",
    "Czym są False negative?\n",
    "    Model żle przewidział rzeczywistą etyketę (klasy 1)\n",
    "\n",
    "<br>\n",
    "\n",
    "W przypadku naszego modelu macierz konfuzji wygląda następująco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(prediction, test_Y)\n",
    "sns.heatmap(confusion_matrix, cmap=\"grey\", annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby mnieć lepszy wgląd w błędy należy ustawić przekątne na wartość 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(confusion_matrix, 0)\n",
    "sns.heatmap(confusion_matrix, cmap=\"grey\", annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak lepiej zrrozumieć False positive and False negative i dlaczego należy zwracać na nie uwagę?\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: centered;\">\n",
    "    <img src=\"Zdjęcia/Szkolenie_2/type_of_errors.jpg\" alt=\"drawing\" style=\"width:500px;\"/>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Należy zakładać, że model nigdy nie będzie miał celności 100%, dlatego trzeba się zastanowić czy lepiej mieć więcej False positivów czy False negativów, ponieważ jedne błędy będą prowadzić do katastrowy, podczas gdy inne do fałszywego alarmu. Wartości te określają parametry **PRECYZJI** i **PEŁNOŚCI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: centered;\">\n",
    "    <img src=\"Zdjęcia/Szkolenie_2/cm.png\" alt=\"drawing\" style=\"width:650px;\"/>\n",
    "</div>\n",
    "\n",
    "Precyzja:\n",
    "\n",
    "$\n",
    "\\text{Precyzja} = \\frac{PP}{PP + FP}\n",
    "$\n",
    "\n",
    "Pełność:\n",
    "\n",
    "$\n",
    "\\text{Pełność} = \\frac{PP}{PP + FN}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Wynik precyzji dla modelu to {metrics.precision_score(prediction, test_Y, average=None)}\")\n",
    "print(f\"Wynik pełnośi dla modelu to {metrics.recall_score(prediction, test_Y, average=None)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Często wygodnie połączyć precyzję i pełność w jedną metrykę zwaną **F1**. Wynik F1 stanowi średnią harmoniczną precyzji i pełności. Standardowa średnia traktuje wszystkie wartości jednakowo, natomiast średnia harmoniczna nadaje większą wagę małym wartością. W rezultacie klasyfikator będzie miał dużą wartość F1, gdy zarówno precyzja i pełność będą miały dużą wartość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Wynik pełnośi dla modelu to {metrics.f1_score(prediction, test_Y, average=None)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UWAGA** Wskaźnik F1 faworyzuje zbliżone do siebie wartości precyzji i pełności, natomiast nie zawsze nam na tym zależy (przykład powyżej)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak uzyskać kompromis pomiędzy precyzjją, a pełnością?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W klasyfikacji wynik każdej próbki zostaje wyliczony na podstawie funkcji decyzyjnej. Zmieniając wartość tego progu, zmieniać się będzie precyzja oraz pełność\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: centered;\">\n",
    "    <img src=\"Zdjęcia/Szkolenie_2/progi.jpg\" alt=\"drawing\" style=\"width:900px;\"/>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Rysując wykres \"wszystkich\" możliwości można dowolnie manipulować wartością precyzji i pełności\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: centered;\">\n",
    "    <img src=\"Zdjęcia/Szkolenie_2/stability.jpg\" alt=\"drawing\" style=\"width:900px;\"/>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Wykres precyzji od pełności\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: centered;\">\n",
    "    <img src=\"Zdjęcia/Szkolenie_2/prec-rec.jpg\" alt=\"drawing\" style=\"width:900px;\"/>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Wykres krzywej ROC (charakterystyki roboczej odbiornika (ang. *receiver operating characteristic*) )\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: centered;\">\n",
    "    <img src=\"Zdjęcia/Szkolenie_2/ROC.jpg\" alt=\"drawing\" style=\"width:900px;\"/>\n",
    "</div>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasyfikacja wieloklasowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasyfikacja nie musi rozwiązywać problemu binarnego (chociaż w głównej mierze będzie do takiej sprowadzana). W powyższym przykładzie istnieją 3 klasy. Otrzymaliśmy jedną celność (która nie jest tym za co się podaje).\n",
    "\n",
    "<br>\n",
    "\n",
    "Jednym podejściem w klasyfikacji więcej niż jednej klasy jest stworzenie n binarnych modeli, uzyskanie wyniku dla każdego z nich i wyvranie modelu, który uzyskał najlepszy wynik. Jest to strategia **jeden przeciw wszystkim** (ang. *one-vs-all OvA*) lub **jeden przeciw reszcie** (ang. *one-vs-rest OvR*).\n",
    "\n",
    "<br>\n",
    "\n",
    "Innym roziązaniem jest wyuczenie modelu dla każdej pary klas, **jeden przeciw jednemu** (*one-vs-one OvO*). Dla N klas należy wytrenować $N*(N-1)/2$ modeli, w naszym przypadku 3 x 2 / 2 = 3, ale dla 10 klas jest to już 10 x 9 / 2= 45\n",
    "\n",
    "<br>\n",
    "\n",
    "Sklearn domyślnie zastosuje strategię OvA, wyjątkiem jest model SVM, gdzie bardziej wydajnym rozwiązaniem jest OvO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier()\n",
    "sgd_clf.fit(train_X, train_Y)\n",
    "results = sgd_clf.decision_function(np.array([[1, 1, 1, 1]]))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie warsztatowe/domowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Zrobić projekt na podstawie tego datasetu: https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset/data\n",
    "\n",
    "2. Oglądnąć szkolenie Adriana Urbana dotyczące algorytmów ML: link..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
